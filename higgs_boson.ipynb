{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('./scripts')\n",
    "\n",
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y_train, X_train, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return np.sum(y_pred == y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    X = (X - np.mean(X, axis=0)) / (np.std(X, axis=0) + 1e-20)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(X, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    d = X.shape[1]\n",
    "    X_poly = np.zeros((X.shape[0], d * (degree + 1)))\n",
    "    X_poly[:, 0] = np.zeros(X.shape[0])\n",
    "    for i in range(0, degree):\n",
    "        X_poly[:, (1 + i * d):((i + 1) * d + 1)] = X ** (i + 1)\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "\n",
    "def cross_validation(y, X, k_indices, k, degree, gamma, lambda_, max_iters, batch_size):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    X_test = X[k_indices[k]]\n",
    "    y_test = y[k_indices[k]]\n",
    "    X_train = np.vstack([X[k_indices[i]] for i in range(k_indices.shape[0]) if not i == k])\n",
    "    y_train = np.hstack([y[k_indices[i]] for i in range(k_indices.shape[0]) if not i == k])\n",
    "        \n",
    "    X_test = build_poly(X_test, degree)\n",
    "    X_train = build_poly(X_train, degree)\n",
    "     \n",
    "    X_train = standardize(X_train)\n",
    "    X_test = standardize(X_test)\n",
    "    \n",
    "    w0 = np.zeros(X_train.shape[1])\n",
    "    w, loss = reg_logistic_regression(y=y_train, tx=X_train, lambda_=lambda_, initial_w=w0, max_iters=max_iters, gamma=gamma, batch_size=batch_size)\n",
    "    \n",
    "    y_train_pred = predict_labels(w, X_train)\n",
    "    y_test_pred = predict_labels(w, X_test)\n",
    "    \n",
    "    acc_train = accuracy(y_train_pred, y_train)\n",
    "    acc_test = accuracy(y_test_pred, y_test)\n",
    "    return acc_train, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree:  2, Lambda: 0.0001: Train: 66.838, Test: 66.820\n",
      "Degree:  2, Lambda:  0.001: Train: 68.762, Test: 67.680\n",
      "Degree:  2, Lambda:   0.01: Train: 66.302, Test: 65.660\n",
      "Degree:  2, Lambda:    0.1: Train: 68.444, Test: 67.220\n",
      "Degree:  2, Lambda:    1.0: Train: 59.489, Test: 59.320\n",
      "Degree:  3, Lambda: 0.0001: Train: 68.744, Test: 67.740\n",
      "Degree:  3, Lambda:  0.001: Train: 69.122, Test: 67.720\n",
      "Degree:  3, Lambda:   0.01: Train: 66.193, Test: 65.900\n",
      "Degree:  3, Lambda:    0.1: Train: 62.698, Test: 61.900\n",
      "Degree:  3, Lambda:    1.0: Train: 63.596, Test: 63.000\n",
      "Degree:  4, Lambda: 0.0001: Train: 62.427, Test: 62.340\n",
      "Degree:  4, Lambda:  0.001: Train: 66.307, Test: 65.420\n",
      "Degree:  4, Lambda:   0.01: Train: 68.558, Test: 67.340\n",
      "Degree:  4, Lambda:    0.1: Train: 67.411, Test: 65.460\n",
      "Degree:  4, Lambda:    1.0: Train: 65.758, Test: 65.800\n",
      "Degree:  5, Lambda: 0.0001: Train: 67.480, Test: 68.200\n",
      "Degree:  5, Lambda:  0.001: Train: 67.296, Test: 66.260\n",
      "Degree:  5, Lambda:   0.01: Train: 60.676, Test: 60.740\n",
      "Degree:  5, Lambda:    0.1: Train: 65.396, Test: 65.380\n",
      "Degree:  5, Lambda:    1.0: Train: 65.471, Test: 64.640\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "seed = 44\n",
    "k_fold = 10\n",
    "\n",
    "max_iters = 200\n",
    "batch_size = 100\n",
    "gamma = 1e-2                    # learning rate\n",
    "    \n",
    "degrees = [2, 3, 4, 5]            # polynomial expansion degree\n",
    "lambdas = np.logspace(-4, 0, 5) # regularization constant\n",
    "\n",
    "\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "\n",
    "# define lists to store the accuracies of training data and test data\n",
    "accs_train = np.zeros((len(degrees), len(lambdas)))\n",
    "accs_test = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "for id_degree, degree in enumerate(degrees):\n",
    "    for id_lambda, lambda_ in enumerate(lambdas):\n",
    "        cur_acc_train = np.zeros(k_fold)\n",
    "        cur_acc_test = np.zeros(k_fold)\n",
    "\n",
    "        for k in range(k_fold):\n",
    "            acc_train, acc_test = cross_validation(y=y_train, X=X_train, k_indices=k_indices, k=k, \n",
    "                                                   degree=degree, gamma=gamma, lambda_=lambda_, \n",
    "                                                   max_iters=max_iters, batch_size=batch_size)\n",
    "\n",
    "            cur_acc_train[k] = acc_train\n",
    "            cur_acc_test[k] = acc_test\n",
    "\n",
    "        accs_train[id_degree, id_lambda] = cur_acc_train.mean()\n",
    "        accs_test[id_degree, id_lambda] = cur_acc_test.mean()\n",
    "        print(f\"Degree: {degree:2}, Lambda: {lambda_:6}: Train: {100 * cur_acc_train.mean():.3f}, Test: {100 * cur_acc_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 67.262\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y_train_whole, X_train_whole, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=False)\n",
    "\n",
    "id_degree, id_lambda = np.unravel_index(np.argmax(accs_test), accs_test.shape)\n",
    "degree, lambda_ = degrees[id_degree], lambdas[id_lambda]\n",
    "\n",
    "X_train_whole = build_poly(X_train_whole, degree)\n",
    "X_train_whole = standardize(X_train_whole)\n",
    "\n",
    "w0 = np.zeros(X_train_whole.shape[1])\n",
    "w, loss = reg_logistic_regression(y=y_train_whole, tx=X_train_whole, lambda_=lambda_, initial_w=w0, max_iters=max_iters, gamma=gamma, batch_size=batch_size)\n",
    "\n",
    "y_train_pred = predict_labels(w, X_train_whole)\n",
    "acc_train = accuracy(y_train_pred, y_train_whole)\n",
    "print(f\"Train accuracy: {100 * acc_train:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = './data/test.csv'\n",
    "_, X_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "X_test = build_poly(X_test, degree)\n",
    "X_test = standardize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = './predictions/predictions.csv'\n",
    "y_test_pred = predict_labels(w, X_test, competition=True)\n",
    "create_csv_submission(ids_test, y_test_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
