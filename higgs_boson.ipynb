{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('./scripts')\n",
    "\n",
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y_train, X_train, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return np.sum(y_pred == y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    X = (X - np.mean(X, axis=0)) / (np.std(X, axis=0) + 1e-20)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(X, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    d = X.shape[1]\n",
    "    X_poly = np.zeros((X.shape[0], d * (degree + 1)))\n",
    "    X_poly[:, 0] = np.zeros(X.shape[0])\n",
    "    for i in range(0, degree):\n",
    "        X_poly[:, (1 + i * d):((i + 1) * d + 1)] = X ** (i + 1)\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "\n",
    "def cross_validation(y, X, k_indices, k, degree, gamma, lambda_, max_iters, batch_size):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    X_test = X[k_indices[k]]\n",
    "    y_test = y[k_indices[k]]\n",
    "    X_train = np.vstack([X[k_indices[i]] for i in range(k_indices.shape[0]) if not i == k])\n",
    "    y_train = np.hstack([y[k_indices[i]] for i in range(k_indices.shape[0]) if not i == k])\n",
    "        \n",
    "    X_test = build_poly(X_test, degree)\n",
    "    X_train = build_poly(X_train, degree)\n",
    "     \n",
    "    X_train = standardize(X_train)\n",
    "    X_test = standardize(X_test)\n",
    "    \n",
    "    w0 = np.zeros(X_train.shape[1])\n",
    "    w, loss = reg_logistic_regression(y=y_train, tx=X_train, lambda_=lambda_, initial_w=w0, max_iters=max_iters, gamma=gamma, batch_size=batch_size)\n",
    "    \n",
    "    y_train_pred = predict_labels(w, X_train)\n",
    "    y_test_pred = predict_labels(w, X_test)\n",
    "    \n",
    "    acc_train = accuracy(y_train_pred, y_train)\n",
    "    acc_test = accuracy(y_test_pred, y_test)\n",
    "    return acc_train, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 Train: 0.7297333333333333, Test: 0.7268000000000001\n",
      "0 1 Train: 0.7251999999999998, Test: 0.7192\n",
      "0 2 Train: 0.7254666666666665, Test: 0.7206\n",
      "0 3 Train: 0.7261111111111112, Test: 0.7218\n",
      "0 4 Train: 0.7086444444444445, Test: 0.7114\n",
      "1 0 Train: 0.7298444444444445, Test: 0.7282\n",
      "1 1 Train: 0.7300888888888888, Test: 0.7296\n",
      "1 2 Train: 0.7289111111111112, Test: 0.7162000000000001\n",
      "1 3 Train: 0.7251777777777778, Test: 0.7256\n",
      "1 4 Train: 0.708288888888889, Test: 0.7106\n",
      "2 0 Train: 0.7253777777777778, Test: 0.7232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/postuvan/EPFL/ML_project1/./scripts/implementations.py:31: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 Train: 0.7270666666666666, Test: 0.7238000000000001\n",
      "2 2 Train: 0.725488888888889, Test: 0.7226\n",
      "2 3 Train: 0.7253111111111111, Test: 0.7246\n",
      "2 4 Train: 0.7056444444444444, Test: 0.7070000000000001\n",
      "3 0 Train: 0.7238444444444444, Test: 0.7251999999999998\n",
      "3 1 Train: 0.7189555555555556, Test: 0.7121999999999999\n",
      "3 2 Train: 0.7240666666666667, Test: 0.722\n",
      "3 3 Train: 0.7253777777777778, Test: 0.7314\n",
      "3 4 Train: 0.7041333333333333, Test: 0.7041999999999999\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "seed = 44\n",
    "k_fold = 10\n",
    "\n",
    "max_iters = 200\n",
    "batch_size = 100\n",
    "gamma = 1e-2                    # learning rate\n",
    "    \n",
    "degrees = [2, 3, 4, 5]            # polynomial expansion degree\n",
    "lambdas = np.logspace(-4, 0, 5) # regularization constant\n",
    "\n",
    "\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "\n",
    "# define lists to store the accuracies of training data and test data\n",
    "accs_train = np.zeros((len(degrees), len(lambdas)))\n",
    "accs_test = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "for id_degree, degree in enumerate(degrees):\n",
    "    for id_lambda, lambda_ in enumerate(lambdas):\n",
    "        cur_acc_train = np.zeros(k_fold)\n",
    "        cur_acc_test = np.zeros(k_fold)\n",
    "\n",
    "        for k in range(k_fold):\n",
    "            acc_train, acc_test = cross_validation(y=y_train, X=X_train, k_indices=k_indices, k=k, \n",
    "                                                   degree=degree, gamma=gamma, lambda_=lambda_, \n",
    "                                                   max_iters=max_iters, batch_size=batch_size)\n",
    "\n",
    "            cur_acc_train[k] = acc_train\n",
    "            cur_acc_test[k] = acc_test\n",
    "\n",
    "        accs_train[id_degree, id_lambda] = cur_acc_train.mean()\n",
    "        accs_test[id_degree, id_lambda] = cur_acc_test.mean()\n",
    "        print(f\"{id_degree} {id_lambda} Train: {cur_acc_train.mean()}, Test: {cur_acc_test.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.703648\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y_train_whole, X_train_whole, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=False)\n",
    "\n",
    "id_degree, id_lambda = np.unravel_index(np.argmax(accs_test), accs_test.shape)\n",
    "degree, lambda_ = degrees[id_degree], lambdas[id_lambda]\n",
    "\n",
    "X_train_whole = build_poly(X_train_whole, degree)\n",
    "X_train_whole = standardize(X_train_whole)\n",
    "\n",
    "w0 = np.zeros(X_train_whole.shape[1])\n",
    "w, loss = reg_logistic_regression(y=y_train_whole, tx=X_train_whole, lambda_=lambda_, initial_w=w0, max_iters=max_iters, gamma=gamma, batch_size=batch_size)\n",
    "\n",
    "y_train_pred = predict_labels(w, X_train_whole)\n",
    "acc_train = accuracy(y_train_pred, y_train_whole)\n",
    "print(f\"Train accuracy: {acc_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = './data/test.csv'\n",
    "_, X_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "X_test = build_poly(X_test, degree)\n",
    "X_test = standardize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = './predictions/predictions.csv'\n",
    "y_test_pred = predict_labels(w, X_test)\n",
    "create_csv_submission(ids_test, y_test_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
